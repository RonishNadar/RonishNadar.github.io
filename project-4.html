<!DOCTYPE HTML>
<!--
  Hyperspace by HTML5 UP
  html5up.net | @ajlkn
  Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
  <head>
    <title>Project | Punch ‘n’ Pop: Rehabilitative Motion-Controlled Game</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
  </head>

  <body class="is-preload">
    <!-- Header -->
    <header id="header">
      <a href="index.html" class="title">Ronish Nadar</a>
      <nav>
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="index.html#one" class="active">Projects</a></li>
          <li><a href="index.html#three">Contact</a></li>
        </ul>
      </nav>
    </header>

    <!-- Wrapper -->
    <div id="wrapper">
      <!-- Main -->
      <section id="main" class="wrapper">
        <div class="inner">
          <h1 class="major">Punch ‘n’ Pop: Rehabilitative Motion-Controlled Game</h1>

          <p>
            Punch ‘n’ Pop is an accessibility-focused system that bridges physical motor exercises with real-time
            digital interaction for users with limited dexterity. The platform fuses camera-based tracking and
            wearable IMU sensing to validate motion, classify strike intensity, and provide immediate feedback through
            scoring and visualization.
          </p>

          <!-- HERO MEDIA -->
          <div class="box">
            <h3>Demo</h3>
            <video controls playsinline style="width: 100%; border-radius: 0.5rem;">
              <source src="images/projects/project-4-demo.mp4" type="video/mp4">
            </video>
            <p style="margin-top: 0.75rem;">
              Replace <code>project-4-demo.mp4</code> with your gameplay demo or system walk-through.
            </p>
          </div>

          <hr />

          <h2>Highlights</h2>
          <ul>
            <li>
              <strong>Accessibility-first design:</strong> Created a rehab-friendly interaction loop that maps
              physical exercises to immediate in-game feedback for motivation and engagement.
            </li>
            <li>
              <strong>Sensor fusion:</strong> Combined OpenCV color tracking (HSV filtering) with MPU6050 IMUs to
              detect multi-quadrant gestures and validate movement.
            </li>
            <li>
              <strong>Strike intensity detection:</strong> Built a high-frequency heuristic (100–200 Hz) using jerk
              to classify strike strength while suppressing noise.
            </li>
            <li>
              <strong>Low-latency wireless:</strong> Implemented ESP32 + ESP-NOW messaging for sub-millisecond
              sensor-to-hub transfer and responsive gameplay.
            </li>
            <li>
              <strong>Realtime engine:</strong> Integrated a Python-based engine for rendering, scoring,
              and data synchronization.
            </li>
          </ul>

          <hr />

          <h2>System Overview</h2>
          <p>
            The system treats each movement as an “input event” backed by both vision and inertial signals.
            Vision estimates position/region (quadrant), while IMU dynamics validate motion quality and classify
            intensity. The ESP32 hub streams fused events into the game engine to update targets, scoring, and session logs
            in real-time.
          </p>

          <div class="box">
            <h3>Architecture</h3>

            <div class="row gtr-50">
              <div class="col-6 col-12-medium">
                <span class="image fit">
                  <img src="images/projects/project-4-overview1.PNG"
                       alt="System block diagram" />
                </span>
              </div>

              <div class="col-6 col-12-medium">
                <span class="image fit">
                  <img src="images/projects/project-4-overview2.PNG"
                       alt="OpenCV HSV tracking pipeline" />
                </span>
              </div>

              <div class="col-6 col-12-medium">
                <span class="image fit">
                  <img src="images/projects/project-4-overview3.PNG"
                       alt="IMU processing and jerk-based strike classifier" />
                </span>
              </div>

              <div class="col-6 col-12-medium">
                <span class="image fit">
                  <img src="images/projects/project-4-overview4.PNG"
                       alt="Gameplay and scoring UI" />
                </span>
              </div>
            </div>
          </div>

          <hr />

          <h2>Technical Breakdown</h2>

          <h3>Vision Tracking (OpenCV)</h3>
          <p>
            The vision pipeline isolates the target color via HSV thresholding and filtering. Detected regions are
            mapped into screen quadrants to infer gesture direction and interaction intent. This gives a stable
            spatial signal even for users with reduced dexterity.
          </p>

          <h3>IMU Processing &amp; Strike Classification</h3>
          <p>
            IMU data from the MPU6050 is processed at high rate (100–200 Hz). A jerk-based heuristic
            (time-derivative of acceleration) distinguishes intentional strikes from slow drift and sensor noise,
            enabling intensity scoring without requiring large range-of-motion.
          </p>

          <h3>Wireless + Game Engine</h3>
          <p>
            ESP32 nodes stream events to a central hub using ESP-NOW for minimal latency.
            The Python engine consumes events for real-time rendering, scoring, and synchronization of session-level
            data (e.g., timestamps, hit rate, intensity distribution) for later analysis.
          </p>

          <hr />

          <h2>Key Takeaways</h2>
          <ul>
            <li>Demonstrates human-centered robotics / accessibility engineering</li>
            <li>Fuses vision + inertial sensing to robustly validate user motion</li>
            <li>Shows embedded networking (ESP-NOW) with real-time performance constraints</li>
            <li>Connects physical interaction to software systems (rendering, scoring, data sync)</li>
          </ul>

          <hr />

          <ul class="actions">
            <li><a href="index.html#one" class="button">Back to Projects</a></li>
            <li>
              <a href="https://github.com/AmrapaliKhandare/punchNPop"
                 class="button icon brands fa-github"
                 target="_blank"
                 rel="noopener noreferrer">GitHub Repo</a>
            </li>
          </ul>
        </div>
      </section>
    </div>

    <!-- Footer -->
    <footer id="footer" class="wrapper style1-alt">
      <div class="inner">
        <ul class="menu">
          <li>&copy; Ronish Nadar. All rights reserved.</li>
          <li>Design: HTML5 UP</li>
        </ul>
      </div>
    </footer>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>
  </body>
</html>
